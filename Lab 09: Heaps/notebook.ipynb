{
  "cells": [
    {
      "metadata": {
        "state": "normal"
      },
      "cell_type": "markdown",
      "source": "# Lab 09: Heaps"
    },
    {
      "metadata": {
        "state": "normal"
      },
      "cell_type": "markdown",
      "source": "## Overview\n\nFor this assignment you will start by modifying the heap data stucture implemented in class to allow it to keep its elements sorted by an arbitrary priority (identified by a `key` function), then use the augmented heap to efficiently compute the running median of a set of numbers."
    },
    {
      "metadata": {
        "state": "normal"
      },
      "cell_type": "markdown",
      "source": "## 1. Augmenting the Heap with a `key` function\n\nThe heap implementation covered in class is for a so-called \"max-heap\" — i.e., one where elements are organized such that the one with the maximum value can be efficiently extracted.\n\nThis limits our usage of the data structure, however. Our heap can currently only accommodate elements that have a natural ordering (i.e., they can be compared using the '`>`' and '`<`' operators as used in the implementation), and there's no way to order elements based on some partial or computed property.\n\nTo make our heap more flexible, you'll update it to allow a `key` function to be passed to its initializer. This function will be used to extract a value from each element added to the heap; these values, in turn, will be used to order the elements. \n\nWe can now easily create heaps with different semantics, e.g.,\n\n- `Heap(len)` will prioritize elements based on their length (e.g., applicable to strings, sequences, etc.)\n- `Heap(lambda x: -x)` can function as a *min-heap* for numbers\n- `Heap(lambda x: x.prop)` will prioritize elements based on their `prop` attribute\n\nIf no `key` function is provided, the default max-heap behavior should be used — the \"`lambda x:x`\" default value for the `__init__` method does just that. \n\nYou will, at the very least, need to update the `_heapify` and `add` methods, below, to complete this assignment. (Note, also, that `pop_max` has been renamed `pop`, while `max` has been renamed `peek`, to reflect their more general nature.)"
    },
    {
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "heap",
          "locked": false,
          "schema_version": 1,
          "solution": true
        },
        "id": "heap",
        "state": "graded",
        "deletable": false,
        "starter_code": "class Heap:\n    def __init__(self, key=lambda x:x):\n        self.data = []\n        self.key  = key\n\n    @staticmethod\n    def _parent(idx):\n        return (idx-1)//2\n        \n    @staticmethod\n    def _left(idx):\n        return idx*2+1\n\n    @staticmethod\n    def _right(idx):\n        return idx*2+2\n    \n    def heapify(self, idx=0):\n        \n            \n    def add(self, x):\n        \n        \n    def peek(self):\n        return self.data[0]\n\n    def pop(self):\n        ret = self.data[0]\n        self.data[0] = self.data[len(self.data)-1]\n        del self.data[len(self.data)-1]\n        self.heapify()\n        return ret\n    \n    def __bool__(self):\n        return len(self.data) > 0\n\n    def __len__(self):\n        return len(self.data)\n\n    def __repr__(self):\n        return repr(self.data)",
        "trusted": true
      },
      "cell_type": "code",
      "source": "class Heap:\n    def __init__(self, key=lambda x:x):\n        self.data = []\n        self.key  = key\n\n    @staticmethod\n    def _parent(idx):\n        return (idx-1)//2\n        \n    @staticmethod\n    def _left(idx):\n        return idx*2+1\n\n    @staticmethod\n    def _right(idx):\n        return idx*2+2\n    \n    def heapify(self, idx=0):\n        i = 0\n        while True:\n            l = Heap._left(i)\n            r = Heap._right(i)\n            maxidx = i\n            if l < len(self.data) and self.key(self.data[l]) > self.key(self.data[i]):\n                maxidx = l\n            if r < len(self.data) and self.key(self.data[r]) > self.key(self.data[maxidx]):\n                maxidx = r\n            if maxidx != i:\n                self.data[i], self.data[maxidx] = self.data[maxidx], self.data[i]\n                i = maxidx\n            else:\n                break\n            \n    def add(self, x):\n        self.data.append(x)\n        i = len(self.data)-1\n        p = Heap._parent(i)\n        while i > 0 and self.key(self.data[i]) > self.key(self.data[p]):\n            self.data[i], self.data[p] = self.data[p], self.data[i]\n            i = p\n            p = Heap._parent(i)\n        \n    def peek(self):\n        return self.data[0]\n\n    def pop(self):\n        ret = self.data[0]\n        self.data[0] = self.data[len(self.data)-1]\n        del self.data[len(self.data)-1]\n        self.heapify()\n        return ret\n    \n    def __bool__(self):\n        return len(self.data) > 0\n\n    def __len__(self):\n        return len(self.data)\n\n    def __repr__(self):\n        return repr(self.data)",
      "execution_count": 24,
      "outputs": []
    },
    {
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "heap_test_1",
          "locked": true,
          "points": 1,
          "schema_version": 1,
          "solution": false
        },
        "id": "heap_test_1",
        "state": "read_only",
        "editable": false,
        "deletable": false,
        "trusted": true
      },
      "cell_type": "code",
      "source": "# (1 point)\n\nfrom unittest import TestCase\nimport random\n\ntc = TestCase()\nh = Heap()\n\nrandom.seed(0)\nfor _ in range(10):\n    h.add(random.randrange(100))\n\ntc.assertEqual(h.data, [97, 61, 65, 49, 51, 53, 62, 5, 38, 33])",
      "execution_count": 25,
      "outputs": []
    },
    {
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "heap_test_2",
          "locked": true,
          "points": 1,
          "schema_version": 1,
          "solution": false
        },
        "id": "heap_test_2",
        "state": "read_only",
        "editable": false,
        "deletable": false,
        "trusted": true
      },
      "cell_type": "code",
      "source": "# (1 point)\n\nfrom unittest import TestCase\nimport random\n\ntc = TestCase()\nh = Heap(lambda x:-x)\n\nrandom.seed(0)\nfor _ in range(10):\n    h.add(random.randrange(100))\n\ntc.assertEqual(h.data, [5, 33, 53, 38, 49, 65, 62, 97, 51, 61])",
      "execution_count": 26,
      "outputs": []
    },
    {
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "heap_test_3",
          "locked": true,
          "points": 2,
          "schema_version": 1,
          "solution": false
        },
        "id": "heap_test_3",
        "state": "read_only",
        "editable": false,
        "deletable": false,
        "trusted": true
      },
      "cell_type": "code",
      "source": "# (2 points)\n\nfrom unittest import TestCase\nimport random\n\ntc = TestCase()\nh = Heap(lambda s:len(s))\n\nh.add('hello')\nh.add('hi')\nh.add('abracadabra')\nh.add('supercalifragilisticexpialidocious')\nh.add('0')\n\ntc.assertEqual(h.data,\n              ['supercalifragilisticexpialidocious', 'abracadabra', 'hello', 'hi', '0'])",
      "execution_count": 27,
      "outputs": []
    },
    {
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "heap_test_4",
          "locked": true,
          "points": 2,
          "schema_version": 1,
          "solution": false
        },
        "id": "heap_test_4",
        "state": "read_only",
        "editable": false,
        "deletable": false,
        "trusted": true
      },
      "cell_type": "code",
      "source": "# (2 points)\n\nfrom unittest import TestCase\nimport random\n\ntc = TestCase()\nh = Heap()\n\nrandom.seed(0)\nlst = list(range(-1000, 1000))\nrandom.shuffle(lst)\n\nfor x in lst:\n    h.add(x)\n\nfor x in range(999, -1000, -1):\n    tc.assertEqual(x, h.pop())",
      "execution_count": 28,
      "outputs": []
    },
    {
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "heap_test_5",
          "locked": true,
          "points": 2,
          "schema_version": 1,
          "solution": false
        },
        "id": "heap_test_5",
        "state": "read_only",
        "editable": false,
        "deletable": false,
        "trusted": true
      },
      "cell_type": "code",
      "source": "# (2 points)\n\nfrom unittest import TestCase\nimport random\n\ntc = TestCase()\nh = Heap(key=lambda x:abs(x))\n\nrandom.seed(0)\nlst = list(range(-1000, 1000, 3))\nrandom.shuffle(lst)\n\nfor x in lst:\n    h.add(x)\n\nfor x in reversed(sorted(range(-1000, 1000, 3), key=lambda x:abs(x))):\n    tc.assertEqual(x, h.pop())",
      "execution_count": 29,
      "outputs": []
    },
    {
      "metadata": {
        "state": "normal"
      },
      "cell_type": "markdown",
      "source": "## 2. Computing the Running Median\n\nThe median of a series of numbers is simply the middle term if ordered by magnitude, or, if there is no middle term, the average of the two middle terms. E.g., the median of the series [3, 1, 9, 25, 12] is **9**, and the median of the series [8, 4, 11, 18] is **9.5**.\n\nIf we are in the process of accumulating numerical data, it is useful to be able to compute the *running median* — where, as each new data point is encountered, an updated median is computed. This should be done, of course, as efficiently as possible.\n\nThe following function demonstrates a naive way of computing the running medians based on the series passed in as an iterable."
    },
    {
      "metadata": {
        "state": "read_only",
        "editable": false,
        "deletable": false,
        "id": "running_medians_naive",
        "trusted": true
      },
      "cell_type": "code",
      "source": "def running_medians_naive(iterable):\n    values = []\n    medians = []\n    for i, x in enumerate(iterable):\n        values.append(x)\n        values.sort()\n        if i%2 == 0:\n            medians.append(values[i//2])\n        else:\n            medians.append((values[i//2] + values[i//2+1]) / 2)\n    return medians",
      "execution_count": 30,
      "outputs": []
    },
    {
      "metadata": {
        "state": "normal",
        "trusted": true
      },
      "cell_type": "code",
      "source": "running_medians_naive([3, 1, 9, 25, 12])",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 31,
          "data": {
            "text/plain": "[3, 2.0, 3, 6.0, 9]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "state": "normal",
        "trusted": true
      },
      "cell_type": "code",
      "source": "running_medians_naive([8, 4, 11, 18])",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 32,
          "data": {
            "text/plain": "[8, 6.0, 8, 9.5]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "state": "normal"
      },
      "cell_type": "markdown",
      "source": "Note that the function keeps track of all the values encountered during the iteration and uses them to compute the running medians, which are returned at the end as a list. The final running median, naturally, is simply the median of the entire series.\n\nUnfortunately, because the function sorts the list of values during every iteration it is incredibly inefficient. Your job is to implement a version that computes each running median in O(log N) time using, of course, the heap data structure!\n\n### Hints\n\n- You will need to use two heaps for your solution: one min-heap, and one max-heap. \n- The min-heap should be used to keep track of all values *greater than* the most recent running median, and the max-heap for all values *less than* the most recent running median — this way, the median will lie between the minimum value on the min-heap and the maximum value on the max-heap (both of which can be efficiently extracted)\n- In addition, the difference between the number of values stored in the min-heap and max-heap must never exceed 1 (to ensure the median is being computed). This can be taken care of by intelligently `pop`-ping/`add`-ing elements between the two heaps."
    },
    {
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "running_median",
          "locked": false,
          "schema_version": 1,
          "solution": true
        },
        "id": "running_median",
        "state": "graded",
        "deletable": false,
        "starter_code": "def running_medians(iterable):\n    ",
        "trusted": true
      },
      "cell_type": "code",
      "source": "def running_medians(iterable):\n    mi = Heap(lambda x:-x)\n    num_mi = 0\n    ma = Heap()\n    num_ma = 0\n    current_med = 0\n    run = []\n    for x in iterable:\n        if x < current_med:\n            ma.add(x)\n            num_ma += 1\n        elif x >= current_med:\n            mi.add(x)\n            num_mi +=1\n        if num_ma - num_mi == 2:\n            mi.add(ma.pop())\n            num_ma -= 1\n            num_mi += 1\n        elif num_mi - num_ma == 2:\n            ma.add(mi.pop())\n            num_mi -= 1\n            num_ma += 1\n        if num_mi > num_ma:\n            run.append(mi.peek())\n            current_med = run[len(run)-1]\n        elif num_ma > num_mi:\n            run.append(ma.peek())\n            current_med = run[len(run) - 1]\n        else:\n            num = mi.peek() + ma.peek()\n            num = num/2\n            run.append((num))\n            current_med = run[len(run) - 1]\n    return run\n        ",
      "execution_count": 57,
      "outputs": []
    },
    {
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "running_median_1",
          "locked": true,
          "points": 2,
          "schema_version": 1,
          "solution": false
        },
        "id": "running_median_1",
        "state": "read_only",
        "editable": false,
        "deletable": false,
        "trusted": true
      },
      "cell_type": "code",
      "source": "# (2 points)\n\nfrom unittest import TestCase\ntc = TestCase()\ntc.assertEqual([3, 2.0, 3, 6.0, 9], running_medians([3, 1, 9, 25, 12]))",
      "execution_count": 58,
      "outputs": []
    },
    {
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "running_median_2",
          "locked": true,
          "points": 2,
          "schema_version": 1,
          "solution": false
        },
        "id": "running_median_2",
        "state": "read_only",
        "editable": false,
        "deletable": false,
        "trusted": true
      },
      "cell_type": "code",
      "source": "# (2 points)\n\nimport random\nfrom unittest import TestCase\ntc = TestCase()\nvals = [random.randrange(10000) for _ in range(1000)]\ntc.assertEqual(running_medians_naive(vals), running_medians(vals))",
      "execution_count": 59,
      "outputs": []
    },
    {
      "metadata": {
        "nbgrader": {
          "grade": true,
          "grade_id": "running_median_3",
          "locked": true,
          "points": 4,
          "schema_version": 1,
          "solution": false
        },
        "id": "running_median_3",
        "state": "read_only",
        "editable": false,
        "deletable": false,
        "trusted": true
      },
      "cell_type": "code",
      "source": "# (4 points) MUST COMPLETE IN UNDER 10 seconds!\n\nimport random\nfrom unittest import TestCase\ntc = TestCase()\nvals = [random.randrange(100000) for _ in range(100001)]\nm_mid   = sorted(vals[:50001])[50001//2]\nm_final = sorted(vals)[len(vals)//2]\nrunning = running_medians(vals)\ntc.assertEqual(m_mid, running[50000])\ntc.assertEqual(m_final, running[-1])",
      "execution_count": 60,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.3",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "mimir": {
      "project_id": "c177e65b-a467-44fb-a2d0-5d9efc6a1fae",
      "last_submission_id": "1076c480-1ba0-4639-806f-b69816c15956",
      "data": {}
    },
    "varInspector": {
      "window_display": false,
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "library": "var_list.py",
          "delete_cmd_prefix": "del ",
          "delete_cmd_postfix": "",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "library": "var_list.r",
          "delete_cmd_prefix": "rm(",
          "delete_cmd_postfix": ") ",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}